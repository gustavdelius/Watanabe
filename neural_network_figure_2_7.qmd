---
title: "Neural Networks and WAIC: Reproducing Figure 2.7"
format:
  html:
    code-fold: true
jupyter: python3
---

This document explains and reproduces Figure 2.7 from Sumio Watanabe's *Mathematical Theory of Bayesian Statistics*, which demonstrates the behavior of generalization errors and information criteria in Singular Statistical Models. We focus specifically on a two-layer neural network with varying numbers of hidden units.

## The Singular Nature of Neural Networks

Neural networks are prime examples of **singular statistical models**. Consider a two-layer neural network with $H$ hidden units mapping a 2D input $x \in \mathbb{R}^2$ to an output probability $f(x;w_{out},w_{in}) \in (0,1)$ without bias terms, structured as:

$$
f(x; w_{out}, w_{in}) = \sigma\left( \sum_{h=1}^H w_{out, h} \sigma(w_{in, h} \cdot x) \right)
$$

where $w_{out} \in \mathbb{R}^H$ are the output weights, $w_{in} \in \mathbb{R}^{H \times 2}$ are the input weights, and $\sigma(t) = 1/(1 + e^{-t})$ is the sigmoid activation function. 

```{mermaid}
%%| fig-cap: "Architecture of the two-layer neural network mapping a 2D input to a single output through $H$ hidden units."
%%| fig-align: "center"
graph LR
    %% Inputs
    x1((x1)):::input_node
    x2((x2)):::input_node
    
    %% Hidden units
    h1((h1)):::hidden_node
    h2((h2)):::hidden_node
    hH((h_H)):::hidden_node
    
    %% Output
    y(("f(x)")):::output_node
    
    %% Connections
    x1 -->|"w_in"| h1
    x1 --> h2
    x1 -.-> hH
    
    x2 --> h1
    x2 --> h2
    x2 -.-> hH
    
    h1 -->|"w_out"| y
    h2 --> y
    hH -.-> y
    
    %% Styling
    classDef input_node fill:#e0f7fa,stroke:#006064,stroke-width:2px;
    classDef hidden_node fill:#fff3e0,stroke:#e65100,stroke-width:2px;
    classDef output_node fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px;
```

Because these relationships use non-linear activations, true parameter values can be mapped to multiple distinct network configurations. For instance:

- **Node Permutation Symmetry**: Swapping two hidden nodes while swapping their inputs and outputs results in the same network mapping.
- **Node Degeneracy**: If the output weight to a hidden node is strictly zero, its input weights can take any value without affecting the output.
- **Activation Symmetries**: Properties of certain activation functions lead to flat parameter submanifolds.

These characteristics mean the mapping from model parameters to probability distributions ($w \mapsto p(x|w)$) is not one-to-one, and the Fisher Information Matrix degenerates. In such singular regions, the Laplace approximation fails, and regular model theorems such as the fundamental AIC expansion ($G_n \approx T_n + \frac{d}{n}$) are radically invalidated.

## Experimental Setup

To investigate this visually, we can replicate the experiment yielding Figure 2.7. The core idea is to establish a **true data-generating process** utilizing a Neural Network with **3 hidden units ($H = 3$)**, and then attempt to fit models of varying complexity ($H \in \{1, 2, 3, 4, 5\}$).

Instead of running MCMC dynamically (which takes considerable execution time for 20 trials), we present the annotated codebase and explain its structure in detail, along with the rendered figure.

### Data Generation

We generate $n=200$ points mapping a 2-dimensional space into a binomial classification (1D):

```python
# The true model is a neural net with 3 hidden units
n = 200
H_true = 3
w_true = np.random.normal(0, 10, size=3*H_true)

X = np.random.uniform(-2, 2, size=(n, 2))
f_X = neural_net(X, w_true, H_true)
Y = np.random.binomial(1, f_X)
```

### Metrics Explored

The script executes 20 parallel trials, evaluating 4 vital measures for each hypothesis $H$:

1. **Generalization Error (GE)** - The ground truth test error. Approximated by testing hypotheses on 10,000 hold-out samples over the Metropolis-Hastings posterior.
2. **AIC** - The classic estimation using standard dimension theory: $AIC = T_n + \frac{d}{n}$ (where $d = 3H$).
3. **ISCV (Leave-One-Out CV)** - Importance Sampling Cross Validation. It consistently tracks Generalization.
4. **WAIC** - Watanabe-Akaike Information Criterion evaluated via posterior predictive limits: $WAIC = T_n + V_n$.

## Reproducing the Figure

Below is the output generated by the Python script `reproduce_figure_2_7.py`, aggregating these comparisons. Notice that the true generalization gap ($GE - S$) follows the same shape as WAIC: 

![Figure 2.7: Comparison of GE, AIC, ISCV, and WAIC against the number of hidden units $H$. Notice how AIC diverges, while WAIC closely shadows True Generalization.](figures/Figure_2.7.png){#fig-2-7}

### Interpretation of Results

The key takeaways from the resulting chart are: 

1. **Standard AIC Fails Dramatically**: Because the neural network is extremely singular, substituting the unadjusted parameter count $d/n$ artificially penalizes complex models exponentially. AIC assumes all parameters contribute to the model's actual power, severely demanding simpler networks when $H \ge 3$, and failing to acknowledge the dimensional reduction governed by the Real Log Canonical Threshold ($\lambda$). 
2. **WAIC Shadows True Generalization (GE)**: Irrespective of $H$, WAIC gracefully evaluates the expected loss. It utilizes the model's functional empirical variance $V_n$ to uniquely recognize non-identifiable parameters without manual tuning.
3. **Overparameterization and Generalization**: When the neural network is overparameterized ($H=4$ or $H=5$ vs $H_{true}=3$), it doesn't hopelessly overfit. Due to singular model theory and Bayesian averaging, WAIC correctly identifies that these extra parameters do not damage out-of-sample performance, plateauing instead of continually diverging. This forms part of the mathematical proof for why modern deep neural networks often eschew tight pruning criteria without immediately overfitting data.

## Full Python Implementation
The complete sampling mechanism involves tracking Metropolis-Hastings trajectories over the singular manifold under a Gaussian Prior:
```python
{{< include reproduce_figure_2_7.py >}}
```
